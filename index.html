<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="description" content="Evaluating Concurrent Robustness of Language Models Across Diverse Challenge Sets">
        <meta name="keywords" content="InfoTabs, Info Tabs">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title> NTSEBench: Cognitive Reasoning Benchmark for Vision Language Models </title>
        <link rel="icon" href="./static/images/msin-removebg-preview.png">
        <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
        <link rel="stylesheet" href="./static/css/bulma.min.css">
        <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
        <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
        <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
        <link rel="stylesheet" href="./static/css/index.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script defer src="./static/js/fontawesome.all.min.js"></script>
        <script src="./static/js/bulma-carousel.min.js"></script>
        <script src="./static/js/bulma-slider.min.js"></script>
        <script src="./static/js/explorer-index.js"></script>
        <script src="./data/results/output_folders.js" defer></script>
        <script src="./data/results/model_scores.js" defer></script>
        <script src="./visualizer/data/data_public.js" defer></script>
    </head>
    <body>
        <nav class="navbar" role="navigation" aria-label="main navigation">
            <div class="navbar-brand">
                <a
                    role="button"
                    class="navbar-burger"
                    aria-label="menu"
                    aria-expanded="false"
                >
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                </a>
            </div>
        </nav>
        <section class="hero">
            <div class="hero-body">
                <div class="container is-max-desktop">
                    <div class="columns is-centered">
                        <div class="column has-text-centered">
                            <h1 class="title is-1 publication-title is-bold">
                                <img src="static/images/msin-removebg-preview.png" style="width:1em;vertical-align: middle" alt="Logo">
                                <span class="infotabs" style="vertical-align: middle">NTSEBench: Cognitive Reasoning Benchmark for Vision Language Models</span>
                            </h1>
                            <div class="is-size-5 publication-authors">
                                <span class="author-block">
                                    <a href="https://www.linkedin.com/in/vatsal-gupta-iitg/">Pranshu Pandya</a>
                                    <sup style="color:#6fbf73;">1</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://www.linkedin.com/in/pranshu-pandya/">Vatsal Gupta</a>
                                    <sup style="color:#6fbf73;">1</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://tushaarkataria.github.io/">Agney S Talwarr</a>
                                    <sup style="color:#6fbf73;">1</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://vgupta123.github.io/">Tushar Kataria</a>
                                    <sup style="color:#ed4b82">2</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://www.cis.upenn.edu/~danroth/">Dan Roth</a>
                                    <sup style="color:#ffac33">3</sup>
                                </span>

                                <span class="author-block">
                                    <a href="https://search.asu.edu/profile/5176374">Vivek Gupta</a>
                                    <sup style="color:#d8bfd8">4</sup>
                                </span>
                            </div>
                            <div class="is-size-5 publication-authors">
                                <span class="author-block">
                                    <sup style="color:#6fbf73;">1</sup>
                                    Indian Institute of Technology-Guwahati,
                                </span>
                                <br>
                                <span class="author-block">
                                    <sup style="color:#ed4b82">2</sup>
                                    University of Utah,
                                </span>
                                <span class="author-block">
                                    <sup style="color:#ffac33">3</sup>
                                    University of Pennsylvania,
                                </span>
                                
                                <span class="author-block">
                                    <sup style="color:#d8bfd8">4</sup>
                                    Arizona State University
                                </span>
                                <br>
                                <span class="paper-block">
                                    <b style="color:#f41c1c">NAACL 2025 Findings</b>
                                </span>
                            </div>
                            <div class="column has-text-centered">
                                <div class="publication-links">
                                    <!-- <span class="link-block">
                                        <a href="https://aclanthology.org/2024.emnlp-main.1237/" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <svg height="260.090482" viewBox="0 0 68 46" width="384.481582" xmlns="http://www.w3.org/2000/svg" fill="white"><path d="m41.977553 0v3.0158h-34.4906476-7.4869054v7.48499 27.97788 7.52133h7.4869054 42.0138966 7.486906 11.012292v-15.00632h-11.012292v-20.49289-7.48499c0-1.57369 0-1.25402 0-3.0158zm-26.967398 17.98578h26.967398v13.0079h-26.967398z" fill="white" fill-rule="evenodd"/></svg>                                            </span>
                                            <span>ACL Anthology</span>
                                        </a>
                                    </span> -->
                                    <span class="link-block">
                                        <a href="https://arxiv.org/abs/2407.10380" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="ai ai-arxiv"></i>
                                            </span>
                                            <span>arXiv</span>
                                        </a>
                                    </span>
                                    <!-- Code Link. -->
                                    <span class="link-block">
                                        <a href="https://github.com/NTSEBench/NTSEBench" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fab fa-github"></i>
                                            </span>
                                            <span>Code</span>
                                        </a>
                                    </span>

                                    <span class="link-block">
                                        <a href="https://ncert.nic.in/national-talent-examination.php?ln=en" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fa fa-user"></i>
                                            </span>
                                            <span>NTSE- Official</span>
                                        </a>
                                    </span>
                                    <!-- Dataset Link.
                                    <span class="link-block">
                                        <a href="https://youtu.be/3sT4u5SCeZc" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fa fa-play"></i>
                                            </span>
                                            <span>Video</span>
                                        </a>
                                    </span> -->
                                    <!-- Twitter Link. -->
                                    <!-- <span class="link-block">
                                        <a href="" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <p style="font-size:18px">üåê</p>
                                            </span>
                                            <span>Twitter</span>
                                        </a>
                                    </span> -->
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <style>
                                      
            .content-table {
              border-collapse: collapse;
              margin: 25px 0;
              font-size: 0.9em;
              min-width: 400px;
              border-radius: 5px 5px 0 0;
              overflow: hidden;
              box-shadow: 0 0 20px rgba(0, 0, 0, 0.15);
            }
            
            .content-table thead tr {
              background-color: #f3e357;
              color: #ffffff;
              text-align: left;
              font-weight: bold;
              font-size: 80%;
            }
            
            .content-table th,
            .content-table td {
              padding: 12px 15px;
              font-size: 80%;

            }
            
            .content-table tbody tr {
              border-bottom: 1px solid #dddddd;
              font-size: 80%;

            }
            
            .content-table tbody tr:nth-of-type(even) {
              background-color: #f3f3f3;
            }
            
            .content-table tbody tr:last-of-type {
              border-bottom: 2px solid #f3e357;
            }
            
            .content-table tbody tr.active-row {
              font-weight: bold;
              color: #f3e357;
            }

            .section-header {
              background-color: #d9d9d9;
              font-weight: bold;
            }
          </style>
        <section class="section">
            <div class="container" style="margin-top: -150px; margin-bottom: -100px;">
                <div class="columns is-centered m-6">
                    <div class="column is-full has-text-centered content">
                        <div>
                            <div class="box m-5">
                                <div class="content has-text-centered">
                                    <img src="static/images/NTSEBench-example.png" alt="geometric reasoning" width="84%">
                                    <p>
                                        <b>
                                            <img src="static/images/msin-removebg-preview.png" style="width:1.0em;vertical-align: middle" alt="Logo">
                                            Examples from the <span class='infotabs'>NTSEBench</span> dataset
                                        </b>
                                        <br>
                                        Three samples of textual, direction, and spatial reasoning questions from the proposed dataset. Solutions to these questions are not included here but are provided in the dataset
                                        <span class="infotabs">NTSEBench</span>
                                        dataset
                                    </p>
                                </div>
                            </div>
                            
                            
                    </div>
                </div>
            </div>
        </section>
        <section class="section">
            <div class="container" style="margin-bottom: 2vh;">
                <!-- Abstract. -->
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Summary and Abstract</h2>
                        <div class="content has-text-justified">
                            <!-- <iframe src="https://drive.google.com/file/d/1ixJTqdV7OGCy5jzu_eP6QUyzz26Vze36/preview" width="100%" height="650"></iframe> -->
                            <p>
                                Cognitive textual and visual reasoning tasks, including puzzles, series, and analogies, demand the ability to quickly reason, decipher, and evaluate patterns both textually and spatially. Due to extensive training on vast amounts of human-curated data, large language models (LLMs) and vision language models (VLMs) excel in common-sense reasoning tasks, but still struggle with more complex reasoning that demands deeper cognitive understanding. We introduce <span class='infotabs'>NTSEBench</span>, a new dataset designed to evaluate cognitive multimodal reasoning and problem-solving skills of large models. The dataset contains 2,728 multiple-choice questions, accompanied by a total of 4,642 images, categorized into 26 different types. These questions are drawn from the nationwide NTSE examination in India and feature a mix of visual and textual general aptitude challenges, designed to assess intelligence and critical thinking skills beyond mere rote learning. We establish baselines on the dataset using state-of-the-art LLMs and VLMs. To facilitate a comparison between open-source and propriety models, we propose four distinct modeling strategies to handle different modalities‚Äîtext and images‚Äîin the dataset instances.

                            </p>
                        </div>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->
        </div>
    </section>

<!-- DATASET SECTION -->
<section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
        <!-- <h1 class="title is-1 InfoTabs"><img src="static/images/msin-removebg-preview.png" style="width:1.0em;vertical-align: middle" alt="Logo"/>InfoTabs Dataset</h1> -->
        <h1 class="title is-1 InfoTabs">
            <img src="static/images/msin-removebg-preview.png" style="width:1em;vertical-align: middle" alt="Logo">
            <span class="infotabs" style="vertical-align: middle"><span class='infotabs'>NTSEBench</span> Dataset</span>
        </h1>
    </div>
</section>

<section class="section">
    <div class="container">
        <div class="columns is-centered has-text-centered">
            <!-- <div class="column is-full-width has-text-centered"> -->
            <div class="column is-four-fifths">
                <h2 class="title is-3">Overview</h2>
                <div class="content has-text-justified">
                    <p>
                        The National Talent Search Examination (NTSE), administered by the National Council of Educational Research and Training (NCERT) in India since 1963, is a nationwide exam for secondary-grade students. The exam consists of two sections designed to assess a wide range of analytical skills: the Mental Ability Test (MAT) and the Scholastic Aptitude Test (SAT). The MAT section evaluates students‚Äô general aptitude, critical thinking, logical and spatial reasoning, and analytical problem-solving skills (for both textual and visual problems). In contrast, the SAT assesses their domain-specific knowledge in science and mathematics. All questions in the NTSE are multiplechoice (MCQ) with one correct option. Questions and options can be text/image or a combination of both, i.e., multi-modal. We aim to create a dataset focused on cognitive reasoning abilities (MAT-type questions). Cognitive Reasoning. Cognitive understanding in the context of <span class='infotabs'>NTSEBench</span> refers to the ability to process information, recognize patterns, draw inferences, and solve problems using critical, logical and analytical reasoning. This aligns with fundamental concepts in cognitive science, such as problem-solving, pattern recognition, and inferential reasoning
                    </p>
                    <style>
                                      
                        .content-table-2 {
                          border-collapse: collapse;
                          margin: 25px 0;
                          font-size: 0.9em;
                          min-width: 400px;
                          border-radius: 5px 5px 0 0;
                          overflow: hidden;
                          box-shadow: 0 0 20px rgba(0, 0, 0, 0.15);
                        }
                        
                        .content-table-2 thead tr {
                          background-color: #209ceeb6;
                          color: #ffffff;
                          text-align: left;
                          font-weight: bold;
                        }
                        
                        .content-table-2 th,
                        .content-table-2 td {
                          padding: 12px 15px;
                        }
                        
                        .content-table-2 tbody tr {
                          border-bottom: 1px solid #dddddd;
                        }
                        
                        .content-table-2 tbody tr:nth-of-type(even) {
                          background-color: #f3f3f3;
                        }
                        
                        .content-table-2 tbody tr:last-of-type {
                          border-bottom: 2px solid #209ceeb6;
                        }
                        
                        .content-table-2 tbody tr.active-row {
                          font-weight: bold;
                          color: #209ceeb6;
                        }
                      </style>
                    <table class="content-table-2">
                            <thead>
                              <tr>
                                <th>Categories</th>
                                <th># Samples</th>
                                <th>Categories</th>
                                <th># Samples</th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td>Series</td>
                                <td>256</td>
                                <td>Non-Verbal Series</td>
                                <td>95</td>
                              </tr>
                              <tr>
                                <td>Alphabet Test</td>
                                <td>94</td>
                                <td>Missing Character</td>
                                <td>127</td>
                              </tr>
                              <tr>
                                <td>Odd one out</td>
                                <td>170</td>
                                <td>Embedded Figure</td>
                                <td>96</td>
                              </tr>
                              <tr>
                                <td>Analogy</td>
                                <td>151</td>
                                <td>Non-Verbal odd one out</td>
                                <td>70</td>
                              </tr>
                              <tr>
                                <td>Coding-Decoding</td>
                                <td>149</td>
                                <td>Non-Verbal Analogy</td>
                                <td>100</td>
                              </tr>
                              <tr>
                                <td>Number and Ranking</td>
                                <td>139</td>
                                <td>Paper Folding & Cutting</td>
                                <td>96</td>
                              </tr>
                              <tr>
                                <td>Blood Relation</td>
                                <td>126</td>
                                <td>Incomplete Figure</td>
                                <td>94</td>
                              </tr>
                              <tr>
                                <td>Mathematical Operations</td>
                                <td>99</td>
                                <td>Figure Partition</td>
                                <td>71</td>
                              </tr>
                              <tr>
                                <td>Puzzle Test</td>
                                <td>95</td>
                                <td>Cube and Dice</td>
                                <td>23</td>
                              </tr>
                              <tr>
                                <td>Syllogisms</td>
                                <td>44</td>
                                <td>Dot problem</td>
                                <td>23</td>
                              </tr>
                              <tr>
                                <td>Statement & Conclusions</td>
                                <td>143</td>
                                <td>Direction Sense</td>
                                <td>36</td>
                              </tr>
                              <tr>
                                <td>Data Sufficiency</td>
                                <td>90</td>
                                <td>Time and Clock</td>
                                <td>51</td>
                              </tr>
                              <tr>
                                <td></td>
                                <td></td>
                                <td>Mirror, Water and Images</td>
                                <td>50</td>
                              </tr>
                              <tr>
                                <td></td>
                                <td></td>
                                <td>Venn diagrams</td>
                                <td>111</td>
                              </tr>
                            </tbody>
                          
                        
                    </table>

                        
                        <p>
                            
                        </p>
                    </div>
                </div>
            </div>
            <!-- <div class="columns is-centered">
                <div class="column" style="margin-right: -20rem;">
                    <div class="content has-text-centered">
                         <img src="static/" alt="data-overview" style="max-width: 50%;">
                        <p>
                            Key statistics of 
                            <img src="static/images/msin-removebg-preview.png" style="width:1.0em;vertical-align: middle" alt="Logo">
                            <span class="infotabs">InfoTabs</span>
                            .
                            <br>
                        </p>
                    </div>
                </div>
                <div class="column">
                    <div class="content has-text-centered">
                        <img src="static/images/.png" alt="" style="max-width: 56%;">
                        <p>
                            Source dataset distribution of
                            <img src="static/images/msin-removebg-preview.png" style="width:1.0em;vertical-align: middle" alt="Logo">
                            <span class="infotabs">InfoTabs</span>
                            .
                           
                        </p>
                    </div>
                </div>
            </div> -->
            <!-- <div class="columns is-centered m-6">
                <div class="column is-full has-text-centered content">
                    <h2 class="title is-3">Examples</h2>
                    <p>
                        One example for each
                        <b>type of perturbation anlaysed</b> within the 
                        <img src="static/images/msin-removebg-preview.png" style="width:1.0em;vertical-align: middle" alt="Logo">
                        <span class="infotabs">MSIN-InfoTabs</span> dataset.
                    </p>
                    <div id="results-carousel" class="carousel results-carousel">
                        <div class="box m-5">
                            <div class="content has-text-centered">
                                <img src="static/images/examples/" alt="exemplar" width="60%">
                                <p>example</p>
                            </div>
                        </div>
                        <div class="box m-5">
                            <div class="content has-text-centered">
                                <img src="static/images/examples/" alt="exemplar" width="60%">
                                <p>example</p>
                            </div>
                        </div>
                        <div class="box m-5">
                            <div class="content has-text-centered">
                                <img src="static/images/examples/" alt="exemplar" width="60%">
                                <p>example</p>
                            </div>
                        </div>
                        <div class="box m-5">
                            <div class="content has-text-centered">
                                <img src="static/images/examples/" alt="exemplar" width="60%">
                                <p>example</p>
                            </div>
                        </div>
                        
                    </div>
                    <br>
                    <br>
                   
                </div>
            </div> -->
        </div>
    </section>

<!--Strategies section-->
<section class="hero is-light is-small">
    <div class="hero-body has-text-centered">

        <h1 class="title is-1 InfoTabs">
            <img src="static/images/msin-removebg-preview.png" style="width:1em;vertical-align: middle" alt="Logo">
            <span class="infotabs" style="vertical-align: middle">Strategies Proposed for analysis</span>
        </h1>
    </div>
</section>
<section class="section">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-full has-text-centered content">

                <div class="content has-text-justified">
                    <p>
                        Evaluating the reasoning abilities of large language models (LLMs) with text-based questions is straightforward. For vision-language models (VLMs), reasoning with vision-text questions is generally straightforward. 
                        Some API access model models, like GPT-4o and Gemini, support multi-image inputs, while many others do not (open-source models like LLaVA-OneVision and Ovis are emerging with this capability). To address these task-specific and input-related dependencies, we propose four strategies to fairly evaluate the reasoning abilities of both open-source and API-based models.
                    </p>

                    <h5>Standard QA</h5>
                    <p> For instances where question type(<i>J</i>) or questions(<i>Q</i>),options(<i>O</i>) and solutions(<i>S</i>) is text(<i>T</i>),we use a standard text-based QA model like GPT3.5-Turbo or Llama3-70b</p>

                    <h5>Image-Only</h5>
                    <p>We propose a modeling approach where questions and all the options are presented to the model as a single image. This image consolidates all relevant textual and visual content exactly as it appears in the examination paper, effectively capturing the entire question, including both textual and visuals. This strategy utilizes the OCR capabilities of VLM models to interpret and analyze the content, enabling them to process both text and visual elements within the same input.</p>

                    <h5>Interleaved model</h5>
                    <p>In this approach, we integrate text with multiple images to create an interwoven context. This method involves placing related textual and visual elements in proximity, enhancing the model‚Äôs ability to draw connections between them.</p>
                    
                    <h5>Standard VQA</h5>
                    <p>
                    Open-source models typically lack the capability to integrate text and images within a single prompt. To enable fair comparisons, we propose an alternative modeling strategy where the question and option images are combined into a single composite image, labeled as Figure 1, Figure 2, etc. This composite image is accompanied by a structured textual prompt that describes different parts of the image, directing the model‚Äôs attention to relevant visual details. The composite image and prompt are then used to evaluate the model‚Äôs performance, testing its ability to interpret and respond to questions based on the integrated visual and textual information.</p>
                </div>
                <!-- <div class="content">
                    <img class="mt-3">
                        Analysing Language Models 
                        <b>Sensitivity to Input Perturbations</b><br>
                        <center><img src="static/images/sensitive.png" style="width:70%"></img></center>
                        <img src="static/images/msin-removebg-preview.png" style="width:1em;vertical-align: middle" alt="Logo">
                        <b>Multi-Set Inoculation framework</b>                            
                    </p>
                </div> -->
                

        </div>

        
    </div>
</div>
</section>
    <!-- RESULTS SECTION -->
    <section class="hero is-light is-small">
        <div class="hero-body has-text-centered">
            
            <h1 class="title is-1 InfoTabs">
            <img src="static/images/msin-removebg-preview.png" style="width:1em;vertical-align: middle" alt="Logo">
                
                Experiment Results</h1>
        </div>
    </section>
    
    <section class="section">
        <div class="container">
            <div class="content has-text-justified">
                <p>The <strong>Analysis</strong> section of the paper presents a comprehensive evaluation of the impact of various strategies on the <span class='infotabs'>NTSEBench</span> dataset. The findings indicate that 
                    <ul>
                    <li>Interleaving text and images performs better than Standard VQA and Image Only strategy for most categories. </li>
                    <li>Multi-modal reasoning is significantly harder. </li>
                    <li>The results reveal that while LLMs generally perform better on the text-only subset of <span class='infotabs'>NTSEBench</span>, the high standard deviation (11.04) indicates significant variability in model performance across different question types. This variability may stem from some overlap between <span class='infotabs'>NTSEBench</span> and other open-source datasets, suggesting that there are still areas where LLMs exhibit limitations in reasoning capabilities </li>
                    <li><span class='infotabs'>NTSEBench</span> presents a challenging task for SOTA LLMs and VLMs. Based on the findings, it is evident that the proposed dataset presents a challenging task for all state of-the-art LLM and VLM models. None of the open-source models achieve accuracy exceeding 50% on text-only questions and 35% on multimodal questions, with propriety models achieving 62% and 42% accuracy respectively.</li>
                </ul>
                <style>
                    table {
                        width: 75%;
                        border-collapse: collapse;
                        border: 1px solid #209cee;
                    }
                    th, td {
                        border: 1px solid #209cee;
                        padding: 10px;
                        text-align: center;
                    }
                    .diagonal {
                        position: relative;
                        background-color: #209cee; /* Background color for the diagonal cell */
                        color: white; /* Text color */
                    }
                    .diagonal::after {
                        content: "";
                        position: absolute;
                        top: 0;
                        left: 0;
                        right: 0;
                        bottom: 0;
                        background: white; /* Color of the diagonal part */
                        transform: skew(-30deg);
                        transform-origin: 0 0;
                        z-index: 1;
                    }
                    .diagonal span {
                        position: relative;
                        z-index: 2; /* Ensure the text appears above the diagonal */
                    }
                </style>
                <section class="section">
                    <div class="container" style="margin-top: -150px; margin-bottom: -100px;">
                        <div class="columns is-centered m-6">
                            <div class="column is-full has-text-centered content">
                                <div id="results-carousel" class="carousel results-carousel">
                                
                                    <div class="box m-5">
                                        <div class="content has-text-centered">
                                            <table class="content-table">
                                                <thead>
                                                    <tr>
                                                        <th><center>Model</center></th>
                                                        <th>SER</th>
                                                        <th>ALP</th>
                                                        <th>ODO</th>
                                                        <th>ANA</th>
                                                        <th>COD</th>
                                                        <th>NUM</th>
                                                        <th>BLR</th>
                                                        <th>MTO</th>
                                                        <th>PUZ</th>
                                                        <th>SYL</th>
                                                        <th>STC</th>
                                                        <th>DAT</th>
                                                        <th>Avg. Per</th>
                                                    </tr>
                                                </thead>
                                                <tbody>
                                                    <tr class="section-header">
                                                        <td colspan="15">Image Only - Zero Shot</td>
                                                    </tr>
                                                    <tr>
                                                        <td>CogVLM-2</td>
                                                        <td>14.84</td>
                                                        <td>17.02</td>
                                                        <td>20.00</td>
                                                        <td>19.87</td>
                                                        <td>24.83</td>
                                                        <td>16.55</td>
                                                        <td>23.81</td>
                                                        <td>20.20</td>
                                                        <td>20.00</td>
                                                        <td>22.73</td>
                                                        <td>22.12</td>
                                                        <td>15.56</td>
                                                        <td>19.79</td>
                                                    </tr>
                                                    <tr>
                                                        <td>InternLM-XComposer2</td>
                                                        <td>18.36</td>
                                                        <td>18.09</td>
                                                        <td>21.65</td>
                                                        <td>19.95</td>
                                                        <td>17.42</td>
                                                        <td>11.51</td>
                                                        <td>15.87</td>
                                                        <td>24.24</td>
                                                        <td>25.26</td>
                                                        <td>31.16</td>
                                                        <td>17.31</td>
                                                        <td>8.89</td>
                                                        <td>17.22</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Qwen-VL-Chat</td>
                                                        <td>29.69</td>
                                                        <td>23.44</td>
                                                        <td>29.44</td>
                                                        <td>45.45</td>
                                                        <td>39.29</td>
                                                        <td>17.97</td>
                                                        <td>22.11</td>
                                                        <td>45.36</td>
                                                        <td>46.97</td>
                                                        <td>45.38</td>
                                                        <td>34.25</td>
                                                        <td>34.18</td>
                                                        <td>33.73</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Gemini 1.5 Pro</td>
                                                        <td>32.42</td>
                                                        <td>31.91</td>
                                                        <td>47.64</td>
                                                        <td>52.32</td>
                                                        <td>52.37</td>
                                                        <td>37.41</td>
                                                        <td>47.29</td>
                                                        <td>49.29</td>
                                                        <td>47.37</td>
                                                        <td>47.13</td>
                                                        <td>38.46</td>
                                                        <td>44.44</td>
                                                        <td>39.55</td>
                                                    </tr>
                                                    <tr>
                                                        <td>GPT-4o</td>
                                                        <td>28.12</td>
                                                        <td>31.91</td>
                                                        <td>41.94</td>
                                                        <td>50.03</td>
                                                        <td>37.14</td>
                                                        <td>52.38</td>
                                                        <td>34.34</td>
                                                        <td>46.34</td>
                                                        <td>53.85</td>
                                                        <td>43.85</td>
                                                        <td>35.38</td>
                                                        <td>38.17</td>
                                                        <td>36.17</td>
                                                    </tr>
                                                    <tr class="section-header">
                                                        <td colspan="14">Image Only - Few Shot</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Gemini 1.5 Pro</td>
                                                        <td>23.32</td>
                                                        <td>23.08</td>
                                                        <td>46.11</td>
                                                        <td>47.97</td>
                                                        <td>24.66</td>
                                                        <td>36.76</td>
                                                        <td>36.59</td>
                                                        <td>32.29</td>
                                                        <td>42.94</td>
                                                        <td>31.71</td>
                                                        <td>32.67</td>
                                                        <td>22.99</td>
                                                        <td>33.37</td>
                                                    </tr>
                                                    <tr>
                                                        <td>GPT-4o</td>
                                                        <td>32.02</td>
                                                        <td>29.67</td>
                                                        <td>50.30</td>
                                                        <td>40.42</td>
                                                        <td>32.19</td>
                                                        <td>35.29</td>
                                                        <td>43.09</td>
                                                        <td>25.00</td>
                                                        <td>46.74</td>
                                                        <td>41.46</td>
                                                        <td>53.47</td>
                                                        <td>34.48</td>
                                                        <td>38.85</td>
                                                    </tr>
                                                    <tr class="section-header">
                                                        <td colspan="14">Standard QA - Zero Shot</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Mixtral-8x7B</td>
                                                        <td>19.76</td>
                                                        <td>19.57</td>
                                                        <td>24.71</td>
                                                        <td>45.52</td>
                                                        <td>14.77</td>
                                                        <td>26.09</td>
                                                        <td>29.37</td>
                                                        <td>29.59</td>
                                                        <td>32.93</td>
                                                        <td>24.32</td>
                                                        <td>53.85</td>
                                                        <td>33.33</td>
                                                        <td>29.48</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Llama-3 70B</td>
                                                        <td>35.18</td>
                                                        <td>26.09</td>
                                                        <td>47.65</td>
                                                        <td>57.93</td>
                                                        <td>36.36</td>
                                                        <td>36.23</td>
                                                        <td>50.79</td>
                                                        <td>31.63</td>
                                                        <td>60.98</td>
                                                        <td>54.05</td>
                                                        <td>52.88</td>
                                                        <td>40.48</td>
                                                        <td>44.18</td>
                                                    </tr>
                                                    <tr>
                                                        <td>GPT-3.5 Turbo</td>
                                                        <td>35.97</td>
                                                        <td>32.61</td>
                                                        <td>40.00</td>
                                                        <td>51.72</td>
                                                        <td>36.36</td>
                                                        <td>25.36</td>
                                                        <td>36.51</td>
                                                        <td>27.55</td>
                                                        <td>46.34</td>
                                                        <td>35.14</td>
                                                        <td>40.38</td>
                                                        <td>32.14</td>
                                                        <td>36.67</td>
                                                    </tr>
                                                    <tr>
                                                        <td>CogVLM-2</td>
                                                        <td>22.27</td>
                                                        <td>21.28</td>
                                                        <td>27.65</td>
                                                        <td>34.44</td>
                                                        <td>22.82</td>
                                                        <td>18.71</td>
                                                        <td>30.95</td>
                                                        <td>19.19</td>
                                                        <td>29.47</td>
                                                        <td>18.18</td>
                                                        <td>28.85</td>
                                                        <td>27.78</td>
                                                        <td>25.13</td>
                                                    </tr>
                                                    <tr>
                                                        <td>InternLM-XComposer2</td>
                                                        <td>21.88</td>
                                                        <td>24.47</td>
                                                        <td>19.41</td>
                                                        <td>36.42</td>
                                                        <td>25.50</td>
                                                        <td>28.78</td>
                                                        <td>25.40</td>
                                                        <td>27.27</td>
                                                        <td>45.26</td>
                                                        <td>40.91</td>
                                                        <td>34.62</td>
                                                        <td>28.89</td>
                                                        <td>29.90</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Qwen-VL-Chat</td>
                                                        <td>30.08</td>
                                                        <td>18.09</td>
                                                        <td>23.53</td>
                                                        <td>31.13</td>
                                                        <td>26.85</td>
                                                        <td>15.11</td>
                                                        <td>24.60</td>
                                                        <td>27.27</td>
                                                        <td>28.26</td>
                                                        <td>13.64</td>
                                                        <td>15.38</td>
                                                        <td>24.44</td>
                                                        <td>23.19</td>
                                                    </tr>
                                                    <tr>
                                                        <td><i>Gemini 1.5 Pro</i></td>
                                                        <td><b>63.67</b></td>
                                                        <td>39.36</td>
                                                        <td>60.00</td>
                                                        <td><b>69.54</b></td>
                                                        <td><b>61.07</b></td>
                                                        <td>68.35</td>
                                                        <td>58.73</td>
                                                        <td>45.45</td>
                                                        <td><b>81.05</b></td>
                                                        <td><b>65.91</b></td>
                                                        <td>70.19</td>
                                                        <td><b>63.33</b></td>
                                                        <td><b>62.22</b></td>
                                                    </tr>
                                                    <tr>
                                                        <td><i>GPT-4o</i></td>
                                                        <td>42.58</td>
                                                        <td>35.11</td>
                                                        <td>55.88</td>
                                                        <td>65.56</td>
                                                        <td>38.26</td>
                                                        <td>42.45</td>
                                                        <td>68.25</td>
                                                        <td>41.41</td>
                                                        <td>69.47</td>
                                                        <td>63.64</td>
                                                        <td>70.19</td>
                                                        <td>43.33</td>
                                                        <td>53.01</td>
                                                    </tr>
                                                    <tr>
                                                        <td><i>LLaVA-OneVision</i></td>
                                                        <td>42.19</td>
                                                        <td>32.98</td>
                                                        <td>50.59</td>
                                                        <td>57.62</td>
                                                        <td>45.64</td>
                                                        <td>36.69</td>
                                                        <td>57.94</td>
                                                        <td>37.37</td>
                                                        <td>64.21</td>
                                                        <td>50.00</td>
                                                        <td>62.50</td>
                                                        <td>46.67</td>
                                                        <td>48.70</td>
                                                    </tr>
                                                    <tr>
                                                        <td><i>Ovis1.6-Gemma2-9B</i></td>
                                                        <td>42.58</td>
                                                        <td>31.91</td>
                                                        <td>50.00</td>
                                                        <td>50.99</td>
                                                        <td>42.95</td>
                                                        <td>46.04</td>
                                                        <td>38.89</td>
                                                        <td>31.31</td>
                                                        <td>53.26</td>
                                                        <td>27.27</td>
                                                        <td>55.77</td>
                                                        <td>33.33</td>
                                                        <td>42.03</td>
                                                    </tr>
                                                    <tr class="section-header">
                                                        <td colspan="14">Standard QA - Few Shot</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Mixtral-8x7B</td>
                                                        <td>27.20</td>
                                                        <td>24.72</td>
                                                        <td>28.14</td>
                                                        <td>50.70</td>
                                                        <td>29.41</td>
                                                        <td>27.41</td>
                                                        <td>33.33</td>
                                                        <td>29.47</td>
                                                        <td>18.99</td>
                                                        <td>#</td>
                                                        <td>55.45</td>
                                                        <td>32.10</td>
                                                        <td>32.44</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Llama-3 70B</td>
                                                        <td>34.00</td>
                                                        <td>16.85</td>
                                                        <td>44.91</td>
                                                        <td>51.41</td>
                                                        <td>36.47</td>
                                                        <td>34.81</td>
                                                        <td>39.84</td>
                                                        <td>32.63</td>
                                                        <td>34.18</td>
                                                        <td>#</td>
                                                        <td>50.50</td>
                                                        <td>34.57</td>
                                                        <td>37.28</td>
                                                    </tr>
                                                    <tr>
                                                        <td>GPT-3.5 Turbo</td>
                                                        <td>30.80</td>
                                                        <td>32.58</td>
                                                        <td>20.96</td>
                                                        <td>47.89</td>
                                                        <td>30.59</td>
                                                        <td>31.11</td>
                                                        <td>30.08</td>
                                                        <td>29.47</td>
                                                        <td>36.71</td>
                                                        <td>#</td>
                                                        <td>40.59</td>
                                                        <td>34.57</td>
                                                        <td>33.21</td>
                                                    </tr>
                                                    <tr>
                                                        <td><i>Gemini 1.5 Pro</i></td>
                                                        <td><b>63.24</b></td>
                                                        <td>37.36</td>
                                                        <td><b>59.28</b></td>
                                                        <td>68.92</td>
                                                        <td>60.27</td>
                                                        <td><b>68.38</b></td>
                                                        <td>58.54</td>
                                                        <td>43.75</td>
                                                        <td>80.43</td>
                                                        <td>63.41</td>
                                                        <td>70.30</td>
                                                        <td>62.07</td>
                                                        <td><b>61.32</b></td>
                                                    </tr>
                                                    <tr>
                                                        <td><i>GPT-4o</i></td>
                                                        <td>42.29</td>
                                                        <td><b>40.66</b></td>
                                                        <td>58.08</td>
                                                        <td>67.57</td>
                                                        <td>44.52</td>
                                                        <td>40.44</td>
                                                        <td><b>69.92</b></td>
                                                        <td><b>46.88</b></td>
                                                        <td>72.83</td>
                                                        <td>63.41</td>
                                                        <td><b>71.29</b></td>
                                                        <td>*</td>
                                                        <td>56.17</td>
                                                    </tr>
                                                    <tr class="section-header">
                                                        <td colspan="14">Advanced Reasoning Models</td>
                                                    </tr>
                                                    <tr>
                                                        <td>OpenAI o1-preview</td>
                                                        <td>80.62</td>
                                                        <td>90.22</td>
                                                        <td>84.05</td>
                                                        <td>73.13</td>
                                                        <td>85</td>
                                                        <td>85.83</td>
                                                        <td>83.61</td>
                                                        <td>83.7</td>
                                                        <td>84.81</td>
                                                        <td>81.08</td>
                                                        <td>72.28</td>
                                                        <td>83.33</td>
                                                        <td><b>81.88</b></td>
                                                    </tr>
                                                    
                                                </tbody>
                                            </table>
                                            <center>
                                                <b>
                                                    Text Only Questions performance
                                                </b>
                                                <br>
                                                <p style="font-size: 0.75em">
                                                    Zero-shot and Few-shot performance of different models across various text-only categories. We report results using two different modelling strategies Image Only and Standard QA. 
                                                    <br>
                                                    italics font for propriety models, i.e., money or API access is required to run these models. The # is due to the category‚Äôs solution contains images thus restricting few shot on text-only models. 
                                                    <br>
                                                    Note: (* )In some models, a common issue arises when a model refrains from providing a response due to safety concerns, often stemming from misinterpretation of the image‚Äôs intent
                                                </p>
                                            </center>
                                        </p>
                                    </div>
                                    </div>
                                    <div class="box m-5">
                                        <div class="content has-text-centered">
                                            <table class="content-table">
                                                <thead>
                                                    <tr>
                                                        <th><center>Model</center></th>
                                                        <th><center>DIR</center></th>
                                                        <th><center>VEN</center></th>
                                                        <th><center>TIM</center></th>
                                                        <th><center>MIS</center></th>
                                                        <th><center>NVS</center></th>
                                                        <th><center>NVO</center></th>
                                                        <th><center>NVA</center></th>
                                                        <th><center>INC</center></th>
                                                        <th><center>MIR</center></th>
                                                        <th><center>CUB</center></th>
                                                        <th><center>PAP</center></th>
                                                        <th><center>EMB</center></th>
                                                        <th><center>FIG</center></th>
                                                        <th><center>DOT</center></th>
                                                        <th><center>Avg. Per</center></th>
                                                    </tr>
                                                </thead>
                                                <tbody>
                                                    <tr class="section-header">
                                                        <td colspan="16"><center>Interleaved - Zero Shot</center></td>
                                                    </tr>
                                                    <tr>
                                                        <td>Qwen-VL-Chat</td>
                                                        <td>28.12</td>
                                                        <td>19.82</td>
                                                        <td>19.61</td>
                                                        <td>12.6</td>
                                                        <td>22.11</td>
                                                        <td>27.14</td>
                                                        <td>22.00</td>
                                                        <td>23.40</td>
                                                        <td>27.17</td>
                                                        <td>15.73</td>
                                                        <td>23.96</td>
                                                        <td>30.21</td>
                                                        <td>8.45</td>
                                                        <td>17.39</td>
                                                        <td>21.26</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Gemini 1.5 Pro</td>
                                                        <td>63.54</td>
                                                        <td>64.86</td>
                                                        <td>70.59</td>
                                                        <td>37.01</td>
                                                        <td>33.68</td>
                                                        <td>25.71</td>
                                                        <td>32.00</td>
                                                        <td>38.30</td>
                                                        <td>35.87</td>
                                                        <td>43.82</td>
                                                        <td>30.21</td>
                                                        <td>36.46</td>
                                                        <td>46.48</td>
                                                        <td>30.43</td>
                                                        <td>42.06</td>
                                                    </tr>
                                                    <tr>
                                                        <td>GPT-4o</td>
                                                        <td>37.50</td>
                                                        <td>50.45</td>
                                                        <td>41.18</td>
                                                        <td>29.92</td>
                                                        <td>16.84</td>
                                                        <td>22.86</td>
                                                        <td>26.00</td>
                                                        <td>23.40</td>
                                                        <td>34.78</td>
                                                        <td>35.96</td>
                                                        <td>27.08</td>
                                                        <td>22.92</td>
                                                        <td>45.07</td>
                                                        <td>17.39</td>
                                                        <td>30.81</td>
                                                    </tr>
                                                    <tr>
                                                        <td>LLaVA-OneVision</td>
                                                        <td>27.27</td>
                                                        <td>39.64</td>
                                                        <td>44.44</td>
                                                        <td>32.00</td>
                                                        <td>14.74</td>
                                                        <td>28.57</td>
                                                        <td>26.00</td>
                                                        <td>26.60</td>
                                                        <td>32.61</td>
                                                        <td>36.59</td>
                                                        <td>26.04</td>
                                                        <td>37.50</td>
                                                        <td>33.80</td>
                                                        <td>26.09</td>
                                                        <td>30.85</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Ovis1.6-Gemma2-9B</td>
                                                        <td>35.42</td>
                                                        <td>36.04</td>
                                                        <td>39.22</td>
                                                        <td>23.62</td>
                                                        <td>25.26</td>
                                                        <td>28.57</td>
                                                        <td>19.00</td>
                                                        <td>32.98</td>
                                                        <td>32.61</td>
                                                        <td>10.11</td>
                                                        <td>29.17</td>
                                                        <td>23.96</td>
                                                        <td>9.86</td>
                                                        <td>21.74</td>
                                                        <td>26.25</td>
                                                    </tr>
                                                    <tr class="section-header">
                                                        <td colspan="16"><center>Interleaved - Few Shot</center></td>
                                                    </tr>
                                                    <tr>
                                                        <td>Gemini 1.5 Pro</td>
                                                        <td>62.37</td>
                                                        <td>63.89</td>
                                                        <td>68.75</td>
                                                        <td>36.29</td>
                                                        <td>31.52</td>
                                                        <td>23.88</td>
                                                        <td>29.9</td>
                                                        <td>36.26</td>
                                                        <td>33.71</td>
                                                        <td>41.86</td>
                                                        <td>27.96</td>
                                                        <td>34.41</td>
                                                        <td>44.12</td>
                                                        <td>20</td>
                                                        <td>39.63</td>
                                                    </tr>
                                                    <tr>
                                                        <td>GPT-4o</td>
                                                        <td>39.78</td>
                                                        <td>52.78</td>
                                                        <td>52.08</td>
                                                        <td>27.42</td>
                                                        <td>17.39</td>
                                                        <td>*</td>
                                                        <td>*</td>
                                                        <td>19.78</td>
                                                        <td>*</td>
                                                        <td>38.37</td>
                                                        <td>33.33</td>
                                                        <td>*</td>
                                                        <td>41.18</td>
                                                        <td>*</td>
                                                        <td>35.79</td>
                                                    </tr>
                                                    
                                                    <tr class="section-header">
                                                        <td colspan="16"><center>Image Only - Zero Shot</center></td>
                                                    </tr>
                                                    <tr>
                                                        <td>CogVLM-2</td>
                                                        <td>18.75</td>
                                                        <td>18.02</td>
                                                        <td>25.49</td>
                                                        <td>14.96</td>
                                                        <td>18.95</td>
                                                        <td>20</td>
                                                        <td>8.00</td>
                                                        <td>12.77</td>
                                                        <td>7.61</td>
                                                        <td>19.10</td>
                                                        <td>16.67</td>
                                                        <td>12.50</td>
                                                        <td>12.68</td>
                                                        <td>4.35</td>
                                                        <td>14.98</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Qwen-VL-Chat</td>
                                                        <td>21.05</td>
                                                        <td>26.13</td>
                                                        <td>27.45</td>
                                                        <td>22.22</td>
                                                        <td>26.32</td>
                                                        <td>21.43</td>
                                                        <td>17.00</td>
                                                        <td>21.28</td>
                                                        <td>19.57</td>
                                                        <td>25.84</td>
                                                        <td>25</td>
                                                        <td>18.75</td>
                                                        <td>18.31</td>
                                                        <td>17.39</td>
                                                        <td>21.98</td>
                                                    </tr>
                                                    <tr>
                                                        <td>InternLM-XComposer2</td>
                                                        <td>20.83</td>
                                                        <td>20.72</td>
                                                        <td>15.69</td>
                                                        <td>17.32</td>
                                                        <td>15.79</td>
                                                        <td>11.43</td>
                                                        <td>10.00</td>
                                                        <td>14.89</td>
                                                        <td>8.70</td>
                                                        <td>19.10</td>
                                                        <td>10.42</td>
                                                        <td>11.46</td>
                                                        <td>22.54</td>
                                                        <td>8.70</td>
                                                        <td>14.82</td>
                                                    </tr>
                                                    <tr>
                                                        <td>Gemini 1.5 Pro</td>
                                                        <td>52.08</td>
                                                        <td>37.84</td>
                                                        <td>49.02</td>
                                                        <td>25.20</td>
                                                        <td>24.21</td>
                                                        <td>24.29</td>
                                                        <td>27</td>
                                                        <td>26.6</td>
                                                        <td>29.35</td>
                                                        <td>32.58</td>
                                                        <td>23.96</td>
                                                        <td>23.96</td>
                                                        <td>42.25</td>
                                                        <td>34.78</td>
                                                        <td>32.36</td>
                                                    </tr>
                                                    <tr>
                                                        <td>GPT-4o</td>
                                                        <td>40.62</td>
                                                        <td>31.53</td>
                                                        <td>33.33</td>
                                                        <td>22.05</td>
                                                        <td>22.11</td>
                                                        <td>25.71</td>
                                                        <td>19</td>
                                                        <td>24.47</td>
                                                        <td>23.91</td>
                                                        <td>26.97</td>
                                                        <td>34.38</td>
                                                        <td>23.96</td>
                                                        <td>42.25</td>
                                                        <td>21.74</td>
                                                        <td>28.00</td>
                                                    </tr>
                                                        <tr class="section-header">
                                                            <td colspan="16"><center>Standard VQA - Zero Shot</center></td>
                                                        </tr>
                                                        <tr>
                                                            <td>CogVLM-2</td>
                                                            <td>15.62</td>
                                                            <td>12.61</td>
                                                            <td>29.41</td>
                                                            <td>11.02</td>
                                                            <td>8.42</td>
                                                            <td>4.29</td>
                                                            <td>6</td>
                                                            <td>3.19</td>
                                                            <td>11.96</td>
                                                            <td>15.73</td>
                                                            <td>9.38</td>
                                                            <td>10.42</td>
                                                            <td>8.45</td>
                                                            <td>17.39</td>
                                                            <td>11.70</td>
                                                        </tr>
                                                        <tr>
                                                            <td>Qwen-VL-Chat</td>
                                                            <td>21.88</td>
                                                            <td>18.92</td>
                                                            <td>27.45</td>
                                                            <td>5.51</td>
                                                            <td>23.16</td>
                                                            <td>22.86</td>
                                                            <td>20</td>
                                                            <td>24.47</td>
                                                            <td>26.09</td>
                                                            <td>8.99</td>
                                                            <td>20.83</td>
                                                            <td>19.79</td>
                                                            <td>8.45</td>
                                                            <td>8.7</td>
                                                            <td>18.36</td>
                                                        </tr>
                                                        <tr>
                                                            <td>InternLM-XComposer2</td>
                                                            <td>25</td>
                                                            <td>20.72</td>
                                                            <td>25.49</td>
                                                            <td>17.32</td>
                                                            <td>18.95</td>
                                                            <td>8.57</td>
                                                            <td>15</td>
                                                            <td>5.32</td>
                                                            <td>16.3</td>
                                                            <td>12.36</td>
                                                            <td>20.83</td>
                                                            <td>10.42</td>
                                                            <td>12.68</td>
                                                            <td>13.04</td>
                                                            <td>15.85</td>
                                                        </tr>
                                                        <tr>
                                                            <td><i>Gemini 1.5 Pro</i></td>
                                                            <td>54.17</td>
                                                            <td><b>49.55</b></td>
                                                            <td><b>62.75</b></td>
                                                            <td><b>37.8</b></td>
                                                            <td>24.21</td>
                                                            <td>24.29</td>
                                                            <td>21</td>
                                                            <td><b>29.79</b></td>
                                                            <td>21.74</td>
                                                            <td><b>46.07</b></td>
                                                            <td>23.96</td>
                                                            <td>23.96</td>
                                                            <td>40.85</td>
                                                            <td><b>26.09</b></td>
                                                            <td><b>34.73</b></td>
                                                        </tr>
                                                        <tr>
                                                            <td><i>GPT-4o</i></td>
                                                            <td>50</td>
                                                            <td>45.95</td>
                                                            <td>39.22</td>
                                                            <td>28.35</td>
                                                            <td><b>32.63</b></td>
                                                            <td><b>25.71</b></td>
                                                            <td><b>26</b></td>
                                                            <td>18.09</td>
                                                            <td>22.83</td>
                                                            <td>40.45</td>
                                                            <td>23.96</td>
                                                            <td><b>28.12</b></td>
                                                            <td>40.85</td>
                                                            <td><b>26.09</b></td>
                                                            <td>32.01</td>
                                                        </tr>
                                                        <tr class="section-header">
                                                            <td colspan="16"><center>Standard VQA - Few Shot</center></td>
                                                        </tr>
                                                        <tr>
                                                            <td><i>Gemini 1.5 Pro</i></td>
                                                            <td><b>61.29</b></td>
                                                            <td>47.22</td>
                                                            <td><b>68.75</b></td>
                                                            <td>32.26</td>
                                                            <td>17.39</td>
                                                            <td>16.42</td>
                                                            <td>18.56</td>
                                                            <td>27.47</td>
                                                            <td>20.22</td>
                                                            <td>44.19</td>
                                                            <td>20.43</td>
                                                            <td>25.81</td>
                                                            <td><b>44.12</b></td>
                                                            <td>25</td>
                                                            <td><b>33.50</b></td>
                                                        </tr>
                                                        <tr>
                                                            <td><i>GPT-4o</i></td>
                                                            <td>41.94</td>
                                                            <td>49.07</td>
                                                            <td>45.83</td>
                                                            <td>27.42</td>
                                                            <td>15.22</td>
                                                            <td>23.88</td>
                                                            <td>22.68</td>
                                                            <td>15.38</td>
                                                            <td>25.84</td>
                                                            <td>34.88</td>
                                                            <td><b>26.88</b></td>
                                                            <td>22.58</td>
                                                            <td>35.29</td>
                                                            <td>25</td>
                                                            <td>29.42</td>
                                                        </tr>
                                                </tbody>
                                            </table>
                                            <center>
                                                <b>
                                                    Multi-Modailty Questions performance
                                                </b>
                                                <br>
                                                <p style="font-size: 0.75em">
                                                    Zero-shot and Few-shot performance of different models across various Text+Vision categories. We report results using 3 different modelling strategies i.e. Interleaved,Image-Only and StandardVQA. 
                                                    <br>
                                                    italics font for propriety models, i.e., money or API access is required to run these models. The # is due to the category‚Äôs solution contains images thus restricting few shot on text-only models. 
                                                    <br>
                                                    Note: (* )In some models, a common issue arises when a model refrains from providing a response due to safety concerns, often stemming from misinterpretation of the image‚Äôs intent.
                                                </p>
                                            </center>
                                            
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>
                We manually conducted an error analysis of 260 questions (10 from each question category) for Gemini 1.5 pro, and we identified distinct patterns in reasoning and error categorization. We have categorised errors based on the cognitive dimensions outlined in section 2. The Sankey diagram in figure 2 illustrates how errors across various question categories correspond to specific error types. A key observation is that many errors arise from Pattern Recognition failures, especially in categories like Alphabet Tests, Non-Verbal Analogy, and Series questions, where the model struggled with recurring patterns and sequence shifts, highlighting challenges in complex pattern-based reasoning. We also noted frequent errors in Spatial Reasoning and Logical Deduction tasks, particularly in spatial or diagrammatic questions like Cube and Dice, Embedded Figure, and Paper Folding & Cutting. These questions often require pattern recognition, shape manipulation, or deducing logical relations from limited visual data. The figure shows that errors in Quantitative Analysis were common in numerical questions like Time and Clock and Mathematical Operations, indicating the model excels in simpler tasks but struggles with complex number sequences and operations. The error distribution reveals key insights into the model‚Äôs strengths and weaknesses, guiding future improvements.

                  
            </div>
            
            <!-- <div class="columns is-centered m-6">
                <div class="column is-full has-text-centered" style='width:1150px'>
                    <h2 class="title is-3">Results on Strategies</h2>
                
                    <div id="results-carousel" class="carousel results-carousel">
                        <div class="box m-5" >
                            <div class="content has-text-centered">
                                <iframe src="static/external_html/finetuning_results.html" title="Fine-tuning Results" style="width:120%;height:450px"></iframe>
                                <p>
                                    Results on the 
                                    <img src="static/images/msin-removebg-preview.png" style="width:1.0em;vertical-align: middle" alt="Logo">
                                    <span class="infotabs">MSIN-InfoTabs</span> dataset
                                   
                                </p>
                            </div>
                        </div>
                        <div class="box m-5">
                            <div class="content has-text-centered">
                                <center>
                                <iframe src="static/external_html/GPT-3.5mesp.html" title="Fine-tuning Results" style="width:60%;height:530px"></iframe>
                                <p>
                                    Results on the 
                                    <img src="static/images/msin-removebg-preview.png" style="width:1.0em;vertical-align: middle" alt="Logo">
                                    <span class="infotabs">MSIN-InfoTabs</span> dataset
                                   
                                </p>
                            </div>
                        </div>
                        <div class="box m-5">
                            <div class="content has-text-centered">
                                <iframe src="static/external_html/LLaMA-2-13bmesp.html" title="Fine-tuning Results" style="width:60%;height:530px"></iframe>
                                <p>
                                    Results on the 
                                    <img src="static/images/msin-removebg-preview.png" style="width:1.0em;vertical-align: middle" alt="Logo">
                                    <span class="infotabs">MSIN-InfoTabs</span> dataset
                                   
                                </p>
                            </div>
                        </div>
                        <div class="box m-5">
                            <div class="content has-text-centered">
                                <iframe src="static/external_html/semp_gpt.html" title="Fine-tuning Results" style="width:50%;height:430px"></iframe>
                                <p>
                                    Results on the 
                                    <img src="static/images/msin-removebg-preview.png" style="width:1.0em;vertical-align: middle" alt="Logo">
                                    <span class="infotabs">MSIN-InfoTabs</span> dataset
                                   
                                </p>
                            </div>
                        </div>
                        <div class="box m-5">
                            <div class="content has-text-centered">
                                <iframe src="static/external_html/semp_llama.html" title="Fine-tuning Results" style="width:60%;height:530px"></iframe>
                                <p>
                                    Results on the 
                                    <img src="static/images/msin-removebg-preview.png" style="width:1.0em;vertical-align: middle" alt="Logo">
                                    <span class="infotabs">MSIN-InfoTabs</span> dataset
                                   
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div> -->
        </div>
    </section>
    <!-- @PAN TODO: bibtex -->
    <section class="hero is-light is-small">
        <div class="hero-body has-text-centered">
            
            <h1 class="title is-1 InfoTabs">BibTeX</h1>
        </div>
    </section>
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <pre>
                @misc{pandya2025ntsebenchcognitivereasoningbenchmark,
                    title={NTSEBENCH: Cognitive Reasoning Benchmark for Vision Language Models}, 
                    author={Pranshu Pandya and Vatsal Gupta and Agney S Talwarr and Tushar Kataria and Dan Roth and Vivek Gupta},
                    year={2025},
                    eprint={2407.10380},
                    archivePrefix={arXiv},
                    primaryClass={cs.CV},
                    url={https://arxiv.org/abs/2407.10380}, 
              }              
                </pre>
        </div>
    </section>
    <section>
        <div class="section" id="org-banners" style="display: flex; width: 100%;">
            <a href="https://www.iitg.ac.in/" target="_blank" rel="external" style="flex: 1; max-width: 25%; display: flex; justify-content: center;">
                <img class="center-block org-banner" src="static/images/guw.png" style="width: 100%; height: auto;">
            </a>
            <a href="https://www.upenn.edu/" target="_blank" class="ext-link" style="flex: 1; max-width: 25%; display: flex; justify-content: center;">
                <img class="center-block org-banner" src="static/images/upenn.png" style="width: 100%; height: auto;">
            </a>
            <a href="https://www.utah.edu/" target="_blank" rel="external" style="flex: 1; max-width: 25%; display: flex; justify-content: center;">
                <img class="center-block org-banner" src="static/images/utah.png" style="width: 100%; height: auto;">
            </a>
            <a href="https://www.asu.edu/" target="_blank" rel="external" style="flex: 1; max-width: 25%; display: flex; justify-content: center;">
                <img class="center-block org-banner" src="static/images/asu.png" style="width: 100%; height: auto;">
            </a>
        </div>
    </section>
    <footer class="footer">
        <!-- <div class="container"> -->
        <div class="content has-text-centered"></div>
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        This website is website adapted from
                        <a href="https://nerfies.github.io/">Nerfies</a>
                        , licensed under a
                        <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
                            Creative
            Commons Attribution-ShareAlike 4.0 International License
                        </a>
                        and maintained by <a href="https://github.com/vatsal-ts/">Vatsal Gupta</a>.


                    </p>
                </div>
            </div>
        </div>
        <!-- </div> -->
    </footer>
</body>
</html>
